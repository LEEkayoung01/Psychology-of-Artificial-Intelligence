{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac6b4683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of        0    1    2    3    4    5    6    7    8    9    ...  775  776  777  \\\n",
      "0        5    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "1        0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "2        4    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "3        1    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "4        9    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "59995    8    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "59996    3    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "59997    5    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "59998    6    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "59999    8    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "\n",
      "       778  779  780  781  782  783  784  \n",
      "0        0    0    0    0    0    0    0  \n",
      "1        0    0    0    0    0    0    0  \n",
      "2        0    0    0    0    0    0    0  \n",
      "3        0    0    0    0    0    0    0  \n",
      "4        0    0    0    0    0    0    0  \n",
      "...    ...  ...  ...  ...  ...  ...  ...  \n",
      "59995    0    0    0    0    0    0    0  \n",
      "59996    0    0    0    0    0    0    0  \n",
      "59997    0    0    0    0    0    0    0  \n",
      "59998    0    0    0    0    0    0    0  \n",
      "59999    0    0    0    0    0    0    0  \n",
      "\n",
      "[60000 rows x 785 columns]>\n",
      "<bound method NDFrame.head of       0    1    2    3    4    5    6    7    8    9    ...  775  776  777  \\\n",
      "0       7    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "1       2    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "2       1    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "3       0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "4       4    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "9995    2    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "9996    3    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "9997    4    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "9998    5    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "9999    6    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "\n",
      "      778  779  780  781  782  783  784  \n",
      "0       0    0    0    0    0    0    0  \n",
      "1       0    0    0    0    0    0    0  \n",
      "2       0    0    0    0    0    0    0  \n",
      "3       0    0    0    0    0    0    0  \n",
      "4       0    0    0    0    0    0    0  \n",
      "...   ...  ...  ...  ...  ...  ...  ...  \n",
      "9995    0    0    0    0    0    0    0  \n",
      "9996    0    0    0    0    0    0    0  \n",
      "9997    0    0    0    0    0    0    0  \n",
      "9998    0    0    0    0    0    0    0  \n",
      "9999    0    0    0    0    0    0    0  \n",
      "\n",
      "[10000 rows x 785 columns]>\n",
      "(60000,) (10000,) (60000, 784) (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# 1. 데이터 준비하기\n",
    "# Data 읽어들이기\n",
    "train_data=pd.read_csv('C:\\AI Psyc\\mnist_train.csv',header=None)\n",
    "print(train_data.head) # 첫번째 열이 target array\n",
    "test_data=pd.read_csv('C:\\AI Psyc\\mnist_test.csv',header=None)\n",
    "print(test_data.head)\n",
    "\n",
    "# Input과 Target 나누고 데이터 형식 변환하기\n",
    "Target_train = train_data.iloc[:,0].to_numpy()\n",
    "Target_test = test_data.iloc[:,0].to_numpy()\n",
    "Input_train = train_data.iloc[:,1:].to_numpy()\n",
    "Input_test = test_data.iloc[:,1:].to_numpy()\n",
    "print(Target_train.shape, Target_test.shape, Input_train.shape, Input_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e3950a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN:\n",
    "    def __init__(self, sizes, epochs, lr):\n",
    "        self.sizes = sizes\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "\n",
    "        # number of nodes in each layer\n",
    "        self.n_input=self.sizes[0]\n",
    "        self.n_hidden=self.sizes[1]\n",
    "        self.n_output=self.sizes[2]\n",
    "\n",
    "        # Weight between input and hidden layer\n",
    "        limit = 1 / np.sqrt(self.n_input)\n",
    "        self.W1 = np.random.uniform(-limit, limit, (self.n_input, self.n_hidden))\n",
    "        \n",
    "        # Weight between hidden layer and output\n",
    "        limit = 1 / np.sqrt(self.n_hidden)\n",
    "        self.W2 = np.random.uniform(-limit, limit, (self.n_hidden, self.n_output))\n",
    "\n",
    "        self.L0 = []\n",
    "        self.L1 = []\n",
    "        self.L2 = []\n",
    "        \n",
    "        # bias vector\n",
    "        self.bias0 = np.zeros((1, self.n_hidden))\n",
    "        self.bias1 = np.zeros((1, self.n_output))\n",
    "\n",
    "    def ReLU(self, x):\n",
    "        return np.maximum(0,x)\n",
    "    \n",
    "    def softmax(self, x):\n",
    "        e_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
    "        return e_x / np.sum(e_x, axis=-1, keepdims=True) \n",
    "        \n",
    "        \n",
    "    def forward_propagation(self, x_train):\n",
    "\n",
    "        W1 = self.W1\n",
    "        W2 = self.W2\n",
    "        \n",
    "        # input layer activations becomes sample\n",
    "        L0= x_train\n",
    "        self.L0 = L0\n",
    "\n",
    "        # input layer to hidden layer 1\n",
    "        z1 = np.dot(L0, W1)\n",
    "        L1= self.ReLU(z1) + self.bias0\n",
    "        self.L1 = L1\n",
    "        \n",
    "        # hidden layer 1 to hidden layer 2\n",
    "        z2 = np.dot(L1, W2)\n",
    "        L2= self.ReLU(z2) + self.bias1\n",
    "        self.L2 = L2\n",
    "\n",
    "        return L2\n",
    "    \n",
    "    def backward_propagation(self, y_train, output):\n",
    "        L0 = np.array(self.L0, ndmin=2)\n",
    "        L1 = np.array(self.L1, ndmin=2)\n",
    "        L2 = np.array(self.L2, ndmin=2)\n",
    "        Target = np.array(y_train.T, ndmin=2)\n",
    "        W1 = self.W1\n",
    "        W2 = self.W2\n",
    "        \n",
    "        # Calculate W2 update\n",
    "        error = output - Target\n",
    "        z2 = np.dot(L1.T, error.T* L2*(1-L2))\n",
    "        \n",
    "        # Calculate W1 update\n",
    "        h_error = np.dot(error.T, W2.T)\n",
    "        z1 = np.dot(L0.T, h_error*L1*(1-L1))\n",
    "\n",
    "        # Update pamameters\n",
    "        W2 += self.lr * z2\n",
    "        W1 += self.lr * z1\n",
    "        \n",
    "        self.W1 = W1\n",
    "        self.W2 = W2\n",
    "        \n",
    "        return [W1, W2]    \n",
    "    \n",
    "    def train(self, train_list, target_list, output_nodes):\n",
    "        for iteration in range(self.epochs):\n",
    "            predict = []\n",
    "            hit_array = []\n",
    "            for x in range(1000):\n",
    "                output = self.forward_propagation(train_list)\n",
    "                output = self.backward_propagation(output, target_list)\n",
    "\n",
    "    def test(self, train_list, test_list, output_nodes):\n",
    "        for iteration in range(self.epochs):\n",
    "            prediction = []\n",
    "            for x in range(1000):\n",
    "                output = self.forward_propagation(Input_train)\n",
    "                hit = 0\n",
    "                if(np.argmax(Target_test[x])) == (np.argmax(output)):\n",
    "                    hit+=1\n",
    "            prediction.append(hit)\n",
    "        plt.plot(prediction)\n",
    "        plt.show()\n",
    "        accuracy_score = np.mean(prediction) / 10 * 100\n",
    "        print(\"Accuracy: \", round(accuracy_score, 2), \"%\")         \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "79858cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_5520\\3779974932.py:67: RuntimeWarning: overflow encountered in multiply\n",
      "  z2 = np.dot(L1.T, error.T* L2*(1-L2))\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_5520\\3779974932.py:71: RuntimeWarning: overflow encountered in multiply\n",
      "  z1 = np.dot(L0.T, h_error*L1*(1-L1))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  10.0 %\n"
     ]
    }
   ],
   "source": [
    "ann = ANN(sizes=[784, 128, 10], epochs=1, lr=0.05)\n",
    "ann.train(Input_train, Target_train, 10)\n",
    "ann.test(Input_test, Target_test, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
